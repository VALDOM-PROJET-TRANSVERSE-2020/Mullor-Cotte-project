{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook_tf_transform.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpmc-39De3Fm"
      },
      "source": [
        "# WHY FAKE NEWS IS A PROBLEM?\n",
        "**Fake news refers to misinformation, disinformation or mal-information which is spread through word of mouth and traditional media and more recently through digital forms of communication such as edited videos, memes, unverified advertisements and social media propagated rumours.Fake news spread through social media has become a serious problem, with the potential of it resulting in mob violence, suicides etc as a result of misinformation circulated on social media.**\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TanaiRJxe3Fq"
      },
      "source": [
        "# BRIEF DESCRIPTION OF DATASET\n",
        "**This dataset consists of about 40000 articles consisting of fake as well as real news. Our aim is train our model so that it can correctly predict whether a given piece of news is real or fake.The fake and real news data is given in two separate datasets with each dataset consisting around 20000 articles each.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkyuGUx_e3Fs"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "3e924d83-20bd-4309-a4ce-c718500c7811"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLQM2IdHfV5q",
        "outputId": "2b3fe7a7-55ab-4e22-d09a-1eadf9089081"
      },
      "source": [
        "!ls\n",
        "%cd /content/drive/My Drive/Colab Notebooks/projet_sopra/input/fake-and-real-news-dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n",
            "/content/drive/My Drive/Colab Notebooks/projet_sopra/input/fake-and-real-news-dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtFsswgHfvfG",
        "outputId": "08426df2-17a0-42c2-d8be-10bfcbd5ece1"
      },
      "source": [
        "%cd fake-and-real-news-dataset/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'fake-and-real-news-dataset/'\n",
            "/content/drive/My Drive/Colab Notebooks/projet_sopra/input/fake-and-real-news-dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKA79zTZe3F6"
      },
      "source": [
        "# LOADING THE NECESSARY LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCdX3tI3e3F8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWqyQbXWe3GF"
      },
      "source": [
        "# IMPORTING THE DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIMQql4Ee3GR"
      },
      "source": [
        "# DATA VISUALIZATION AND PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrITcogj7mxi"
      },
      "source": [
        "**Import data in tf dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am-njqT-NPTF"
      },
      "source": [
        "true_dataset = tf.data.experimental.CsvDataset(filenames = ['True.csv'], record_defaults = [tf.string, tf.string], select_cols=[0,1], header=True)\r\n",
        "false_dataset = tf.data.experimental.CsvDataset(filenames = ['Fake.csv'], record_defaults = [tf.string, tf.string], select_cols=[0,1], header=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbiFBPu0sgL3",
        "outputId": "affefffb-953a-4095-9ce9-b76f5b2df0b9"
      },
      "source": [
        "for idx, row in enumerate(true_dataset):\r\n",
        "    \r\n",
        "    if idx == 3:\r\n",
        "      print (row)\r\n",
        "      break"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'FBI Russia probe helped by Australian diplomat tip-off: NYT'>, <tf.Tensor: shape=(), dtype=string, numpy=b'WASHINGTON (Reuters) - Trump campaign adviser George Papadopoulos told an Australian diplomat in May 2016 that Russia had political dirt on Democratic presidential candidate Hillary Clinton, the New York Times reported on Saturday. The conversation between Papadopoulos and the diplomat, Alexander Downer, in London was a driving factor behind the FBI\\xe2\\x80\\x99s decision to open a counter-intelligence investigation of Moscow\\xe2\\x80\\x99s contacts with the Trump campaign, the Times reported. Two months after the meeting, Australian officials passed the information that came from Papadopoulos to their American counterparts when leaked Democratic emails began appearing online, according to the newspaper, which cited four current and former U.S. and foreign officials. Besides the information from the Australians, the probe by the Federal Bureau of Investigation was also propelled by intelligence from other friendly governments, including the British and Dutch, the Times said. Papadopoulos, a Chicago-based international energy lawyer, pleaded guilty on Oct. 30 to lying to FBI agents about contacts with people who claimed to have ties to top Russian officials. It was the first criminal charge alleging links between the Trump campaign and Russia. The White House has played down the former aide\\xe2\\x80\\x99s campaign role, saying it was \\xe2\\x80\\x9cextremely limited\\xe2\\x80\\x9d and that any actions he took would have been on his own. The New York Times, however, reported that Papadopoulos helped set up a meeting between then-candidate Donald Trump and Egyptian President Abdel Fattah al-Sisi and edited the outline of Trump\\xe2\\x80\\x99s first major foreign policy speech in April 2016. The federal investigation, which is now being led by Special Counsel Robert Mueller, has hung over Trump\\xe2\\x80\\x99s White House since he took office almost a year ago. Some Trump allies have recently accused Mueller\\xe2\\x80\\x99s team of being biased against the Republican president. Lawyers for Papadopoulos did not immediately respond to requests by Reuters for comment. Mueller\\xe2\\x80\\x99s office declined to comment. Trump\\xe2\\x80\\x99s White House attorney, Ty Cobb, declined to comment on the New York Times report. \\xe2\\x80\\x9cOut of respect for the special counsel and his process, we are not commenting on matters such as this,\\xe2\\x80\\x9d he said in a statement. Mueller has charged four Trump associates, including Papadopoulos, in his investigation. Russia has denied interfering in the U.S. election and Trump has said there was no collusion between his campaign and Moscow. '>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEfVKurc7uva"
      },
      "source": [
        "**Join text and title**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9epNz60lzli"
      },
      "source": [
        "def preprocess_join_sentence(s1, s2):\r\n",
        "    ret = tf.strings.reduce_join([s1, s2],separator=\" \", axis=-1)\r\n",
        "    return ret\r\n",
        "\r\n",
        "true_dataset = true_dataset.map(preprocess_join_sentence)\r\n",
        "false_dataset = false_dataset.map(preprocess_join_sentence)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skppFInZbh5I",
        "outputId": "0c8513a3-2af5-48c1-9182-bb1a6d2a5fdb"
      },
      "source": [
        "for idx, row in enumerate(true_dataset):\r\n",
        "  if idx == 3:\r\n",
        "    print (row)\r\n",
        "    break"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'FBI Russia probe helped by Australian diplomat tip-off: NYT WASHINGTON (Reuters) - Trump campaign adviser George Papadopoulos told an Australian diplomat in May 2016 that Russia had political dirt on Democratic presidential candidate Hillary Clinton, the New York Times reported on Saturday. The conversation between Papadopoulos and the diplomat, Alexander Downer, in London was a driving factor behind the FBI\\xe2\\x80\\x99s decision to open a counter-intelligence investigation of Moscow\\xe2\\x80\\x99s contacts with the Trump campaign, the Times reported. Two months after the meeting, Australian officials passed the information that came from Papadopoulos to their American counterparts when leaked Democratic emails began appearing online, according to the newspaper, which cited four current and former U.S. and foreign officials. Besides the information from the Australians, the probe by the Federal Bureau of Investigation was also propelled by intelligence from other friendly governments, including the British and Dutch, the Times said. Papadopoulos, a Chicago-based international energy lawyer, pleaded guilty on Oct. 30 to lying to FBI agents about contacts with people who claimed to have ties to top Russian officials. It was the first criminal charge alleging links between the Trump campaign and Russia. The White House has played down the former aide\\xe2\\x80\\x99s campaign role, saying it was \\xe2\\x80\\x9cextremely limited\\xe2\\x80\\x9d and that any actions he took would have been on his own. The New York Times, however, reported that Papadopoulos helped set up a meeting between then-candidate Donald Trump and Egyptian President Abdel Fattah al-Sisi and edited the outline of Trump\\xe2\\x80\\x99s first major foreign policy speech in April 2016. The federal investigation, which is now being led by Special Counsel Robert Mueller, has hung over Trump\\xe2\\x80\\x99s White House since he took office almost a year ago. Some Trump allies have recently accused Mueller\\xe2\\x80\\x99s team of being biased against the Republican president. Lawyers for Papadopoulos did not immediately respond to requests by Reuters for comment. Mueller\\xe2\\x80\\x99s office declined to comment. Trump\\xe2\\x80\\x99s White House attorney, Ty Cobb, declined to comment on the New York Times report. \\xe2\\x80\\x9cOut of respect for the special counsel and his process, we are not commenting on matters such as this,\\xe2\\x80\\x9d he said in a statement. Mueller has charged four Trump associates, including Papadopoulos, in his investigation. Russia has denied interfering in the U.S. election and Trump has said there was no collusion between his campaign and Moscow. ', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvw_0r_W2mh2"
      },
      "source": [
        "### Add labels to dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_lo08LlZczU"
      },
      "source": [
        "cat_true = tf.data.Dataset.from_tensor_slices(np.ones(len(list(true_dataset)), dtype=int))\r\n",
        "cat_false = tf.data.Dataset.from_tensor_slices(np.zeros(len(list(false_dataset)), dtype=int))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj09KwCJZjdu"
      },
      "source": [
        "true_dataset = tf.data.Dataset.zip((true_dataset, cat_true))\r\n",
        "false_dataset = tf.data.Dataset.zip((false_dataset, cat_false))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggohx0giaB8c"
      },
      "source": [
        "full_dataset = false_dataset.concatenate(true_dataset)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqCBNRny4Tne",
        "outputId": "836953c4-d9da-4e47-9b02-857530d84068"
      },
      "source": [
        "for idx, row in enumerate(full_dataset):\r\n",
        "  if idx == 3:\r\n",
        "    print (row)\r\n",
        "    break"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b' Trump Is So Obsessed He Even Has Obama\\xe2\\x80\\x99s Name Coded Into His Website (IMAGES) On Christmas day, Donald Trump announced that he would  be back to work  the following day, but he is golfing for the fourth day in a row. The former reality show star blasted former President Barack Obama for playing golf and now Trump is on track to outpace the number of golf games his predecessor played.Updated my tracker of Trump s appearances at Trump properties.71 rounds of golf including today s. At this pace, he ll pass Obama s first-term total by July 24 next year. https://t.co/Fg7VacxRtJ pic.twitter.com/5gEMcjQTbH  Philip Bump (@pbump) December 29, 2017 That makes what a Washington Post reporter discovered on Trump s website really weird, but everything about this administration is bizarre AF. The coding contained a reference to Obama and golf:  Unlike Obama, we are working to fix the problem   and not on the golf course.  However, the coding wasn t done correctly.The website of Donald Trump, who has spent several days in a row at the golf course, is coded to serve up the following message in the event of an internal server error: https://t.co/zrWpyMXRcz pic.twitter.com/wiQSQNNzw0  Christopher Ingraham (@_cingraham) December 28, 2017That snippet of code appears to be on all https://t.co/dkhw0AlHB4 pages, which the footer says is paid for by the RNC? pic.twitter.com/oaZDT126B3  Christopher Ingraham (@_cingraham) December 28, 2017It s also all over https://t.co/ayBlGmk65Z. As others have noted in this thread, this is weird code and it s not clear it would ever actually display, but who knows.  Christopher Ingraham (@_cingraham) December 28, 2017After the coding was called out, the reference to Obama was deleted.UPDATE: The golf error message has been removed from the Trump and GOP websites. They also fixed the javascript  =  vs  ==  problem. Still not clear when these messages would actually display, since the actual 404 (and presumably 500) page displays a different message pic.twitter.com/Z7dmyQ5smy  Christopher Ingraham (@_cingraham) December 29, 2017That suggests someone at either RNC or the Trump admin is sensitive enough to Trump s golf problem to make this issue go away quickly once people noticed. You have no idea how much I d love to see the email exchange that led us here.  Christopher Ingraham (@_cingraham) December 29, 2017 The code was f-cked up.The best part about this is that they are using the  =  (assignment) operator which means that bit of code will never get run. If you look a few lines up  errorCode  will always be  404          (@tw1trsux) December 28, 2017trump s coders can t code. Nobody is surprised.  Tim Peterson (@timrpeterson) December 28, 2017Donald Trump is obsessed with Obama that his name was even in the coding of his website while he played golf again.Photo by Joe Raedle/Getty Images.'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2eM0q3174EE"
      },
      "source": [
        "**Formate sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttqepq_OhNe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01598a9-2736-4df4-a0bc-c1eef32992d2"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "def rm_stopwords(text):\r\n",
        "  stop = set(stopwords.words('english'))\r\n",
        "  nltk.download('punkt')\r\n",
        "\r\n",
        "  stop = list(stop)\r\n",
        "  ret = tf.strings.strip(text)\r\n",
        "\r\n",
        "  for i in stop:\r\n",
        "    ret = tf.strings.regex_replace(ret, '\\\\b'+i+'\\\\b', '')\r\n",
        "  # Remove adding spaces\r\n",
        "\r\n",
        "  ret = tf.strings.regex_replace(ret, ' +', ' ')\r\n",
        "  return ret\r\n",
        "\r\n",
        "def preprocess_sentence(sentence, label):\r\n",
        "  ret = tf.strings.lower(sentence) # to lower\r\n",
        "\r\n",
        "  ret = tf.strings.strip(ret) # create list of words \r\n",
        "\r\n",
        "  # Denoise text\r\n",
        "  ret = tf.strings.regex_replace(ret, r'[^\\x00-\\x7f]','') # Removing adding chars to decode in UTF-8\r\n",
        "  ret = tf.strings.regex_replace(ret, '<[^<]+?>', '') # Removing HTML chars\r\n",
        "  ret = tf.strings.regex_replace(ret, '\\[[^]]*\\]', '') # Removing the square brackets\r\n",
        "  ret = tf.strings.regex_replace(ret, 'http\\S+', '') # Removing URL's\r\n",
        "\r\n",
        "  ret = tf.strings.regex_replace(ret, '!\"#$%&(),-./:;<=>?@\\t\\n', '') # Keras tokenizer filter\r\n",
        "  ret = tf.strings.regex_replace(ret, '[^A-Za-z0-9]+', ' ') # remove ponctuation\r\n",
        "\r\n",
        "  ret = rm_stopwords(ret) # Removing stopwords\r\n",
        "\r\n",
        "  return ret, label\r\n",
        "\r\n",
        "full_dataset = full_dataset.map(preprocess_sentence)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Q44zZzkZ16",
        "outputId": "98706efb-2e09-4cad-f3b0-ee468032d7a8"
      },
      "source": [
        "for idx, row in enumerate(full_dataset):\r\n",
        "  if idx == 3:\r\n",
        "    print(row)\r\n",
        "    break\r\n",
        "    \r\n",
        "    "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'trump obsessed even obamas name coded website images christmas day donald trump announced would back work following day golfing fourth day row former reality show star blasted former president barack obama playing golf trump track outpace number golf games predecessor played updated tracker trump appearances trump properties 71 rounds golf including today pace pass obama first term total july 24 next year pic twitter com 5gemcjqtbh philip bump pbump december 29 2017 makes washington post reporter discovered trump website really weird everything administration bizarre af coding contained reference obama golf unlike obama working fix problem golf course however coding done correctly website donald trump spent several days row golf course coded serve following message event internal server error pic twitter com wiqsqnnzw0 christopher ingraham cingraham december 28 2017that snippet code appears pages footer says paid rnc pic twitter com oazdt126b3 christopher ingraham cingraham december 28 2017it also others noted thread weird code clear would ever actually display knows christopher ingraham cingraham december 28 2017after coding called reference obama deleted update golf error message removed trump gop websites also fixed javascript vs problem still clear messages would actually display since actual 404 presumably 500 page displays different message pic twitter com z7dmyq5smy christopher ingraham cingraham december 29 2017that suggests someone either rnc trump admin sensitive enough trump golf problem make issue go away quickly people noticed idea much love see email exchange led us christopher ingraham cingraham december 29 2017 code f cked best part using assignment operator means bit code never get run look lines errorcode always 404 tw1trsux december 28 2017trump coders code nobody surprised tim peterson timrpeterson december 28 2017donald trump obsessed obama name even coding website played golf photo joe raedle getty images'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3hIj-EFXTgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904dd558-24cf-4449-c4d3-44e3ce2fce38"
      },
      "source": [
        "!pip install -q tensorflow-text\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4MB 11.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmYi8yhdsLpM"
      },
      "source": [
        "### Glove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23ZxWLI13hWK"
      },
      "source": [
        "**Count max occurences in dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph19RA42M4GN"
      },
      "source": [
        "from collections import Counter\r\n",
        "\r\n",
        "def freq_words(inputs, max_size=15000): # input dataset, returns list\r\n",
        "  count = Counter()\r\n",
        "\r\n",
        "  numpy_sentences = []\r\n",
        "  for sentences, labels in full_dataset.take(-1):  # take all elements in dataset\r\n",
        "      numpy_sentences.extend(tf.strings.split(sentences).numpy())\r\n",
        "      numpy_labels = labels.numpy()\r\n",
        "  list_words = numpy_sentences\r\n",
        "\r\n",
        "  for word in list_words:\r\n",
        "    # print(word)\r\n",
        "    count[word] += 1\r\n",
        "  result = [word for word, num in count.most_common(max_size)]\r\n",
        "  return result\r\n",
        "\r\n",
        "max_freq_words = freq_words(full_dataset)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcUBohUDVMU0"
      },
      "source": [
        "max_freq_words = [w.decode(\"utf-8\") for w in max_freq_words]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z11NdJkKZxyw",
        "outputId": "fb81cdad-b19b-4abe-bddd-49b1a8ca6680"
      },
      "source": [
        "max_freq_words[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trump',\n",
              " 'said',\n",
              " 'u',\n",
              " 'president',\n",
              " 'would',\n",
              " 'people',\n",
              " 'one',\n",
              " 'state',\n",
              " 'new',\n",
              " 'also']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9LYaDiML_fj"
      },
      "source": [
        "**Find this occurences in the pretrained glove file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7DysO8KL-1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a4c406-314e-4069-9b31-1f195c6fec49"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n",
        "# Build vocabulary and relevent vector\r\n",
        "words = []\r\n",
        "# Adding 2 empty vector of dimension 100 which will be used in padding and unknown token(word)\r\n",
        "# According to previous knowledge i have idea that it contains 400,000 words\r\n",
        "# Added extra 2 rows because when we will use inside TextVectorization add blank i.e. '' and ['UNK'] inside vocabulary\r\n",
        "\r\n",
        "counter = 0\r\n",
        "\r\n",
        "vectors = np.zeros((10000, 100))\r\n",
        "\r\n",
        "with open(f\"../glove-twitter/glove.twitter.27B.100d.txt\") as f:\r\n",
        "    lines = f.readlines()\r\n",
        "\r\n",
        "    for idx, line in enumerate(lines):\r\n",
        "      if counter >= 10000-2:\r\n",
        "        break\r\n",
        "\r\n",
        "      split_line = line.split()\r\n",
        "      \r\n",
        "      if split_line[0] in max_freq_words:\r\n",
        "        words.append(split_line[0])\r\n",
        "        vectors[counter+2] = split_line[1:]\r\n",
        "        counter+=1\r\n",
        "\r\n",
        "print(f\"Number of words are {len(words)}\")\r\n",
        "print(f\"Shape of vector is {vectors.shape}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words are 9998\n",
            "Shape of vector is (10000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owibnaA1NFuG",
        "outputId": "d8d510b2-1bb1-4c6f-9672-d2f234f9fa7a"
      },
      "source": [
        "vectors[:3]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ],\n",
              "       [ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
              "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ],\n",
              "       [ 0.6047   ,  0.89542  ,  0.27923  ,  0.033489 ,  0.15873  ,\n",
              "         0.18522  ,  0.30722  ,  0.47445  ,  0.44484  ,  0.7045   ,\n",
              "         0.39528  , -0.19818  , -2.3884   ,  0.095433 ,  0.10782  ,\n",
              "         0.26263  ,  0.36582  , -0.6385   , -0.22938  , -0.34722  ,\n",
              "         0.10977  ,  0.37367  , -0.068053 , -0.39421  ,  0.43471  ,\n",
              "        -2.1794   , -0.47111  ,  0.087237 ,  0.57989  , -0.020883 ,\n",
              "        -0.0695   ,  0.25771  , -0.5019   ,  0.41154  ,  1.2178   ,\n",
              "         0.47976  , -0.31574  ,  0.52983  ,  0.041575 ,  0.44973  ,\n",
              "        -1.5363   , -0.096062 , -0.27531  ,  0.52771  ,  0.028587 ,\n",
              "         0.047935 , -0.5973   , -0.051772 ,  0.11377  , -0.4049   ,\n",
              "        -0.54857  , -0.65916  , -0.38132  , -0.39519  ,  0.42961  ,\n",
              "         0.74531  , -0.50838  ,  0.40392  ,  0.62699  , -0.24798  ,\n",
              "        -0.25386  ,  0.21867  , -0.072132 , -0.51783  , -0.054186 ,\n",
              "        -0.66391  , -0.58224  ,  0.060621 , -0.54001  ,  0.72242  ,\n",
              "         0.13349  , -0.070261 , -0.059061 , -0.035474 , -0.53649  ,\n",
              "        -0.3755   ,  0.11234  , -0.3409   , -0.13406  ,  0.0078872,\n",
              "         0.81973  , -0.075774 ,  0.10947  ,  0.26919  , -0.069167 ,\n",
              "         0.27475  , -0.90546  ,  0.54632  , -0.6847   ,  0.35787  ,\n",
              "        -0.015019 ,  0.42209  , -0.06252  , -0.33265  , -0.60945  ,\n",
              "        -0.23269  , -0.40932  ,  0.51566  ,  0.84726  ,  0.020946 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7lBhvDzV4i-",
        "outputId": "db09e662-cf85-4cc3-9a98-94980fe0afb7"
      },
      "source": [
        "words[1120:1130]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sir',\n",
              " 'math',\n",
              " 'moving',\n",
              " 'losing',\n",
              " 'nights',\n",
              " 'rap',\n",
              " 'sam',\n",
              " 'march',\n",
              " 'truly',\n",
              " 'killing']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4XMjb7SsKCt",
        "outputId": "9e72185e-3fc7-42da-b21d-b7f62db3804c"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n",
        "# TextVectorization hyper parameter\r\n",
        "max_vocab = 10000\r\n",
        "max_len = 300\r\n",
        "vectorize_layer_glove = TextVectorization(max_tokens=max_vocab,\r\n",
        "                                                    standardize=\"lower_and_strip_punctuation\",\r\n",
        "                                                    split=\"whitespace\",\r\n",
        "                                                    output_mode=\"int\",\r\n",
        "                                                    output_sequence_length=max_len,\r\n",
        "                                                    vocabulary=words)\r\n",
        "\r\n",
        "\r\n",
        "# Vocabulary set into layer\r\n",
        "vectorize_layer_glove.set_vocabulary(words)\r\n",
        "print(f\"Top 10 words {vectorize_layer_glove.get_vocabulary()[:10]}\")\r\n",
        "print(f\"Some words {vectorize_layer_glove.get_vocabulary()[-1010:-1000]} \\n\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 words ['', '[UNK]', 'rt', 'de', 'n', 'la', 'e', 'u', 'en', 'el']\n",
            "Some words ['aspen', 'hsbc', 'assigned', 'relying', 'plc', 'bailout', 'complained', 'opposing', 'interfere', 'accompany'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w77OJDFFsUDN"
      },
      "source": [
        "def int_vectorize_text(text, label):\r\n",
        "  text = tf.expand_dims(text, -1)\r\n",
        "  return vectorize_layer_glove(text), label\r\n",
        "\r\n",
        "train_data_tokenized = full_dataset.map(int_vectorize_text)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sikwvvb3BJka",
        "outputId": "d9187d51-8038-4434-97e2-187316003163"
      },
      "source": [
        "model_glove = tf.keras.models.Sequential()\r\n",
        "model_glove.add(tf.keras.layers.Input(shape=(1,), dtype=tf.string))\r\n",
        "model_glove.add(vectorize_layer_glove)\r\n",
        "model_glove.predict([\"expect terror fbi steps use isis stings 21st century wire says real terrorist threat thing ...\"])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1009, 2933, 4447, 2580,  312, 7691,    1,    1, 3899, 4622,  353,\n",
              "         111, 4894, 4184,  162,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxjpD0rI0XPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05185d2-76c0-4da0-f29e-0fc6817ecb8c"
      },
      "source": [
        "for idx, row in enumerate(train_data_tokenized):\r\n",
        "  if idx == 1:\r\n",
        "    print(row)\r\n",
        "    break"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1, 300), dtype=int64, numpy=\n",
            "array([[ 662, 6713, 6659,    1,  572, 3190,    1, 5838,  221, 3866, 5393,\n",
            "        6172, 6267, 9655,   70,  137,   31, 9360,   10,  229,  102, 4496,\n",
            "        9298, 8162,    1, 2446, 5838,    1, 4275, 2150, 4447,  813, 2169,\n",
            "        6659,  782, 8162,  572, 5838, 2303, 7134,    1,   30, 1002,  324,\n",
            "        2447, 6659, 2367, 9372, 1476,    1,  662, 1407,  871, 4469, 2776,\n",
            "        3190, 5412, 2315, 5871, 4248,  254,    1,    1,  251, 6659, 5739,\n",
            "        7002,   64, 6665, 1847, 1217,    1, 6349, 1328, 1407,  871,  873,\n",
            "         310,  205, 7308,   30, 1002, 1165, 6659, 1145,    1,    1,    9,\n",
            "        2108, 2545,  236,  746, 3101, 1561, 2447, 6857,  473, 5580,  144,\n",
            "        3260, 6659,  109, 6659, 1480, 6645,  873,  251,  214,    1,    1,\n",
            "        4469, 3802, 9846, 4685,    1, 3190, 4665,  726,  240, 1047, 3652,\n",
            "        6624, 4741, 8305, 5871, 4248,  732,   64, 1162,    1,  159,   75,\n",
            "           1, 1407, 4608, 3802, 4685,    1,    1, 1226, 2195,  236,  746,\n",
            "         526, 4374, 6624, 4471, 5012, 8245,  422, 3802, 4665, 1768, 2119,\n",
            "        1162,    1,  886,    1, 2303, 1212, 1951, 2447,  886, 3140, 4665,\n",
            "        1845, 2776, 9634, 1847,    1,    1, 2512, 1249,  125,   14,    1,\n",
            "        4458,  536, 9754, 2073,    1,  109, 8615, 2711, 9949, 1358,  306,\n",
            "         161,  121,  196,    1, 9437, 3312,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDFp_AiVng2R",
        "outputId": "41fe3721-a761-4f50-ee57-2494deb9afc7"
      },
      "source": [
        "len(vectors[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN27WAForl3F"
      },
      "source": [
        "### Prepare data to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZXYqxoVro8W"
      },
      "source": [
        "# Model params\r\n",
        "batch_size = 256\r\n",
        "epochs = 10\r\n",
        "embed_size = 100\r\n",
        "maxlen = 300\r\n",
        "max_features = 10000"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvWBijprsD2Q"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O1u2Wj8sDHn"
      },
      "source": [
        "#Defining Neural Network\r\n",
        "model = Sequential()\r\n",
        "#Non-trainable embeddidng layer\r\n",
        "model.add(Embedding(max_features, output_dim=embed_size, weights=[vectors], input_length=maxlen, trainable=False))\r\n",
        "#LSTM \r\n",
        "model.add(LSTM(units=128 , return_sequences = True))\r\n",
        "model.add(LSTM(units=64))\r\n",
        "model.add(Dense(units = 32 , activation = 'relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\r\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGfBpf3uubNM",
        "outputId": "50cfe118-318f-437e-d2da-bac38a544916"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 300, 128)          117248    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,168,769\n",
            "Trainable params: 168,769\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxEGtL-85NSD"
      },
      "source": [
        "### TODO : add validation dataset and shuffle data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vo1h89w1sJK"
      },
      "source": [
        "full_dataset = train_data_tokenized.map(lambda x_text, x_label: (x_text, tf.expand_dims(x_label, -1)))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nS4VRMxqoDJ",
        "outputId": "978d365b-a59b-4afe-9d4c-5e5640d27591"
      },
      "source": [
        "len(list(full_dataset))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFUf2MV8obfi"
      },
      "source": [
        "DATASET_SIZE = len(list(full_dataset))\r\n",
        "\r\n",
        "train_size = int(0.8 * DATASET_SIZE)\r\n",
        "test_size = int(0.2 * DATASET_SIZE)\r\n",
        "\r\n",
        "full_dataset = full_dataset.shuffle(buffer_size=DATASET_SIZE, seed=42)\r\n",
        "train_dataset = full_dataset.take(train_size)\r\n",
        "test_dataset = full_dataset.skip(train_size)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cJWKSxH1ypE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8bd024-f76b-4c82-e628-2f78bc1bbd31"
      },
      "source": [
        "for idx, row in enumerate(train_dataset):\r\n",
        "  if idx == 1:\r\n",
        "    print(row)\r\n",
        "    break"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1, 300), dtype=int64, numpy=\n",
            "array([[ 484, 4508,  291, 6659,    1,  138,  207, 4173, 2274, 2864, 3384,\n",
            "        3008, 7256, 9662,    1,   98,   64,  174,  484, 4508,  291, 6659,\n",
            "        3152, 3384, 2864,  187, 1480, 1145, 2362,    1, 1922, 4398, 6891,\n",
            "          41,  551,   98, 5308, 7745,  229,  273,  526, 7745,    1, 8986,\n",
            "           1,  273,  526,  229,   33,  214,  265, 1972,    1,  273,  604,\n",
            "        9478, 4597, 4508, 6659, 8143, 1828,   60,   32, 1145,  861, 2195,\n",
            "        2222,  719,  311, 1483,    1,    1, 1242,  144,    1, 6430, 2447,\n",
            "           1,    1,    1, 8986,    1, 6430, 4544, 8115, 1228, 1342,  431,\n",
            "           1,  432,    1, 8986,    1,   29,    1, 5220, 3972, 1833,    1,\n",
            "         846,  795,  170, 8592,  120, 2609, 4597, 4508, 6659,    1, 5372,\n",
            "          91,   29,    1, 8986,  159,    1, 1471,  170,  585,  271,   93,\n",
            "          29,   64,   10,   41, 6659,   91, 2372, 6704,    1,  273,  207,\n",
            "          21,  120,   33,  120,  166,   92, 1003,  523, 1479, 7575, 5497,\n",
            "        8986,  159,   57,    1,    1, 4308, 4275,  911,   36, 1003,  523,\n",
            "        1659,  143,  402,  380,   58,  538,  269, 1719,  523, 6659,  120,\n",
            "        1736, 1160,  151,    1,    1, 1259,    1,  544, 1617, 1640,  111,\n",
            "         544, 1617, 1640, 8986, 2964,  194, 3402,  598,  114, 1228,   52,\n",
            "           1, 4703,    1, 1242, 8986, 5423, 1726, 4329, 2612, 1390, 1823,\n",
            "        2787,  888,    1, 3129, 1036,   29,   82, 6928,  236,  378,  273,\n",
            "         604,    1, 8986,  159,    1,   82, 3162,  737,   41,   44,    1,\n",
            "          44,    1, 1160, 8986, 6659, 3250, 2880,   21,  625,    1,  857,\n",
            "          60,   10, 1145,  861, 2195, 1036,  159, 2232, 4125, 1239, 6659,\n",
            "        4387, 8615,   36,   44,  194,   52,  395,   44,  482,  599, 2274,\n",
            "         482,  585, 2274,  313,  164,  530, 8682,  311,   67, 6659,  159,\n",
            "         170, 1734,  940,   10, 1438, 2953,   33,  305, 1490, 8986, 1547,\n",
            "          36, 6659,  159,   87,  846,   70,  762, 2296,  344,  793,  164,\n",
            "        3085, 1172,   53,  737,  345,  581, 3301, 6659,  352, 8986, 3124,\n",
            "        4826, 6803,    1]])>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnmpSJ4ifSRp",
        "outputId": "de6d571a-066b-42f4-a05d-70c535284991"
      },
      "source": [
        "from tensorflow.python.client import device_lib\r\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 18023635697200740924\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11153436864\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 18430811517388179845\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05TuOdrwKK0l"
      },
      "source": [
        "# Train for 2 epochs\r\n",
        "model.fit(train_dataset, batch_size = batch_size, validation_data=test_dataset, epochs=2, steps_per_epoch=20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}